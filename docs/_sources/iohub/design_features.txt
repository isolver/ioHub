============================
Features and Design Overview
============================

The following overview gives a good understanding of how the ioHub works with the experiment creation library and run-time called [PsychoPy](http://www.psychopy.org), and outlines many of the ioHub's useful features. While this overview is detailed, the great thing about the ioHub is that you really do not need to know any of this to *actually use the ioHub* in your psychopy scripts. This overview is intended for those interested in how it is currently implemented and works. If you want to just get down to business and start making experiments, you should check out the ioHub Tutorial section of the wiki {To Be Created, Sorry}.

The main features (existing and desired) of the ioHub when running in parallel with PsychoPy are

* Truly parallel processing of experiment run-time and experiment device inputs. This can be 'forced' to be a literal statement by setting the affinity of PsychoPy and the ioHub to be different core(s) on multi-core systems.
* A single time base for the experiment run-time and all device time stamps, currently selfishly called the ioHub time, making it easy to calculate time delta's, manual reaction times, and saccadic reaction times for example.
* A single API and event model for each device type and associated event types. The pyEyeTrackerInterface is an example if this. Other device types can also likely take advantage from a similar approach; for example Analog to Digital ( and D/A ) cards / boxes, TTL devices, etc.
* Attempt to make the use of the ioHub as simple to use as possible. Users of the API should not need to know about the underlying technical design unless they want too.
* Correct device time stamp's as much as possible for the *offset* that exists when the device time-stamp is using a different time-base than the ioHub time-base. Correct device time stamp's as much as possible for the *drift* that occur's over time when a device is using a physically different timing crystal or mechanism than the ioHub time-base. Correct device time stamp's as much as possible for *delay* that can exist between when the physical real world event occurred that the ioHub Event is representing and the time-stamp given to that event by the device, as well as any additional delay taken in handing the computer event to the ioHub itself. All of these corrections will vary in accuracy greatly from device to device; from being not corrected for at all; to being corrected for based on tested averages and other statistical assumptions; to being corrected for very accurately. Each supported device type and where applicable device model will be discussed in detail.
* Make the API consistent.
* Make the API compatible with PsychoPy.

The below diagram represents a high level block structure of the different elements often in play during a typical ioHub usage scenario.

![ioHub Block Diagram](https://sites.google.com/a/isolver-software.com/iohubimages/home/ioHub_Diagram.png)

#There are four to five main components to consider when using the ioHub API.

## 1. The PsychoPy Process:
The experiment scripting module and run-time environment run in a python interpreter. The PsychoPy process (also referred to as the experiment process)runs the standard PsychoPy distribution 1.74.03 or greater as well as a few ioHub related classes used for interfacing the experiment run-time with the ioHub Process. The ioHub classes of most interest for use by your Psychopy script will likely be:
* **[ioHub.psychopyIOHubRuntime.SimpleIOHubRuntime](./SimpleIOHubRuntime-API)**: This is a utility class that can be extended, with the run method written to contain the PsychoPy experiment script logic. See the *startingTemplate* example, which can literally be copied and then used as a starting point for a new experiment using this method. Using the SimpleIOHubRuntime utility class provides many built in features and methods that make working with PsychoPy and the ioHub quite simple. All the examples written so far use this utility class wrapper.
* **[ioHub.client.ioHubConnection](./ioHubConnection-API)**: This class is used to create the ioHub process, communicate with the ioHub process via a simple UDP based messaging framework, and terminate the ioHub process gracefully. By using the methods supported in ioHubConnection, an experiment run-time process can create the list of ioHubDeviceView objects necessary to represent each registered device type for the experiment and get a list of public method names that are valid for each device type based on some simple Python introspection. ioHubConnection can call arbitrary methods of the ioHub Server class that runs in the ioHub process and receive the results, including requesting a list of all new events that have occurred across all devices, sorted chronologically, since the last call to getEvents() or the clearEvents() methods. When an experiment is created using a class that extends ioHub.psychopyIOHubRuntime.SimpleIOHubRuntime, and attribute called '.hub' is automatically created for you that is an instance of ioHubConnection.
* **[ioHub.client.ioHubDeviceView](./ioHubDeviceView-API)**: This class is the experiment process representation of a device that the ioHub is monitoring and / or controlling. All devices accessed from the experiment process are based on this class. The class allows for transparent access to all *public* methods of an ioHub device that is being managed from the ioHub process by the experiment process itself. This includes the ability to access device specific events.

## 2. The ioHub Process:
The majority of the ioHub code base runs as a separate process (and therefore in a separate Python interpreter) than the experiment run-time process. As an end user of PsychoPy and the ioHub, there is little that you *need* to know about the code running in the ioHub Process. Everything that the Psychopy script interacts with is based on the experiment run-time / client side classes of the ioHub.

In general though, the ioHub runs using an asynchronous non-blocking model. The *asynchronous* part relies on *micro threads* cooperatively slicing the main python sript thread time up, so no Python threads are created by the ioHub core itself (although some devices do create native threads in their C / C++ DLLs that are outside the Python GIL). This has the advantage that no context switching needs to occur by the ioHub core when it handles UDP requests from the experiment-runtime, polls various devices for new events, or sends responses back to the experiment run-time based on a message request. Instead all these tasks are occurring cooperatively at a micro thread level (*threads* defined and implemented within the program itself, not using the OS). This means that much more time can be spent actually doing work in the program logic vs. it being spent on OS context switches and potential thrashing.

The *non-blocking* part relies on modifications to some core Python modules and classes, for example Socket, that allow a micro thread to be waiting for a resource, like data on a socket, without having to block the thread and without having to create another thread to do so.

In implementation, the ioHub uses the gevent (which uses greenlet for mirco threads, or green threads) module to achieve both of the above functions, as well as some custom code for a couple areas where gevent does not provide non-blocking alternatives.

There are **many up sides** to this approach compared to adding threads on threads within your script, particularly in Python because of the negative interaction between how the Python G.I.L. switches between threads in version below Python 3.2 (remember in Python the GIL only allows one Python thread to execute at a time) and how OS's try to schedule threads on multi-core systems. The short of it is that in many situations a multi-threaded Python app will run *slower* than a single threaded python app performing the same task in sequence.

The one down-side to using this type of asynchronous, non-blocking approach, and this is an **important downside**, is that it absolutely relies on all the micro-threads / greenlets being able to operate in fast, quick chunks of work that do not block. If one task blocks for 0.5 seconds, the whole program is blocked for 0.5 seconds. This is a very important point to remember if you ever write an ioHub device or implement the pyEyeTrackerInterface for and eye tracker. This is something you can forget about as a *user* of the ioHub from the experiment process writing a psychopy script (at least as of writing), because this issue issue something that is tested for and bench-marked by the implementer's of the ioHub Process code base. Anything you do in the experiment process can not in general impact the ioHub process performance.

As described in the ##PsychoPy Process## section above, there are also some *client side* classes in the ioHub that allows the experiment run-time process to access ioHub functionality *as if* it was running on the same process as Psychopy.

## 3. A Set of Devices:
The ioHub connects to and / or monitors a set of devices that have been defined for use by the experiment process in the ioHub configuration .yaml file. Device events can be read by the ioHub using a periodic polling method, or events can be registered with the ioHub by an external device API using an event based callback method. The Parallel Port device is an example of a polled device that generated TTL Input events. The Keyboard and Mouse (on Windows at least) are examples of devices that register new events with the associated device's event callback. Note that on Windows, if a Keyboard or Mouse device is created for your experiment, a separate periodic callback is created that calls the pythoncom.PumpWaitingMessages() about every 4 msec (TODO: make the callback interval settable via the ioHub .yaml configuration file for the experiment), which is what in turn caused the event callbacks to be triggered. So really in Windows, for Keyboard and Mouse events both the polling and event callback models are used. ;)

## 4. The pyEyeTrackerInterface:
If you are running an eye tracking experiment, your eye tracker may be able to use the ioHub infrastructure to control and access eye data if your eye tracker manufacturer (or a kind volunteer) has implemented the hardware independent python eye tracking API called the pyEyeTrackerInterface for their eye tracking hardware. The pyEyeTrackerInterface *is the eye tracker device* API as far as the ioHub is concerned. See the [pyEyeTrackerInterface](https://github.com/isolver/ioHub/wiki/EyeTrackerInterface-API) section of the wiki for more details.

##5. Data Persistence via the ioDataStore.
All events that pass through the ioHub can be saved directly by the ioHub server process, in the *ioDataStore* (in all the examples, this is enabled by default). The ioDataStore currently uses a HDF5 file type to organize and store data persistently to disk, and numpy records to represent event data read from the file in memory.

This includes being able to send text messages from the experiment run-time process to the ioHub process and have these saved to a Message Event table within the file as well. With this functionality in mind, it is interesting to note that the experiment process is both the client / recipient of events from the ioHub, as well as a device itself to the ioHub, which sends Message events when the experiment script instructs it to.

The ioDataStore API uses the [pyTables](http://www.pytables.org/moin) module on the back end to achieve the in-memory and file based data representations.

### Retrieving Data from the ioHub ioDataStore

While an experiment, experiment session, and condition centric mid level API is being developed to access all the events that have been saved, allowing simple row selection based on where clauses, and retrieved in enumerated chunks as numpy arrays into memory n an as needed basis for direct use within scipy and or matplotlib for example; in the mean time the HDF5 files can be viewed quite will using the HDF Groups freely available, open source, [HDF5 Viewer](http://www.hdfgroup.org/hdf-java-html/hdfview/).

# Block Diagram Connection Points

## ioHub to PsychoPy (bidirectional)

The Psychopy Process communicates with the ioHub Process using the UDP network protocol at this time. UDP was chosen after testing Pipes and TCP/IP as well on both Windows and Linux. UDP had the lowest delay of the protocols tested on both OS's, and is much more OS independent than Pipes.

The general IPC design using UDP is based on a simple message passing model:
* The Psychopy Process sends a message to the ioHub Process using the ioHub.client.ioClient class via UDP.
* The ioHub Process receives the message, unpacks the message contents, and processes it.
* The ioHub Process sends a reply to the Psychopy Process indicating if the message was successfully processed or not.
* The Psychopy Process receives the ioHub reply and unpacks it. If the message was successfully processed the reply includes any return value the ioHub process sent based on the message request.

Notes:

* The experiment process message send - ioHub response received IPC pattern is currently implemented as a blocking call on the experiment process. So calling getEvents() from within your experiment will not return until the ioHub process response is received. Fortunately the IPC delay is very low (usually about 0.3 msec on average, <= 1.0 msec maximum). See the *Overhead of the ioHub...* section below for more details.    A non-blocking IPC pattern could also be implemented relatively easily in the future if this turns out to be a useful or desirable feature. This would increase the complexity of working with the ioHub process from the experiment processes / user scripts POV though.

## Devices to ioHub (unidirectional or bidirectional)

The way the ioHub *connects* to a given device (or *monitors* a device) is obviously totally device dependent. When possible, OS independent options are given priority over OS dependent options.

Some devices only require a unidirectional connection, in the sense that the device only ever *sends* information to the ioHub. These types of devices can be called *Producer Devices* as they only produce data, events, samples, that the ioHub (as the *Consumer* of the devices data) either polls for or receives via an event callback. Examples of producer devices in the ioHub are the keyboard, mouse, and joystick.

Some devices require a unidirectional connection, but the device is only ever *receiving* information or commands from the ioHub.  These types of devices can be called *Consumer Devices*, as the ioHub is the Producer of data that the device consumes. Depending on your experimental requirements, consumer only devices may be better off not being connected to the ioHub at all. Instead it may be better if the Experiment Process directly connects to the device and sends data or commands to it. The advantage of using the ioHub for consumer only devices is that the ioHub could still be logging the data / events being sent to the consumer device to the ioDataStore. There currently are no consumer only devices implemented in the ioHub.

Other devices have bidirectional communication with the ioHub, and are therefore both Producer's and Consumer's. In this case the ioHub can send data, or issue commands to the device as well as receive data from the device. The eye tracker implementation (pyEyeTrackerInterface) of the ioHub is an example of a bidirectional device interface. The parallel port is bidirectional because you can read port state change events from the device, or you can send a byte value to the device to set it's state so it can be read by another external system. The mouse device is also bidirectional, as you ca not only read events from the device, but you can also set the mouse position on the screen using the devices setPosition() method.

### Currently Supported Device Types and Associated Event Types

**Windows XP and Windows 7 are the only currently supported OS's**

Please refer to the [ioHub API](./ioHub-API) for a current list of supported device classes, associated events, and for the pyEyeTrackerInterface

## ioHub to ioDataStore

Please refer to the above section on *Data Persistence via the ioDataStore*.

***