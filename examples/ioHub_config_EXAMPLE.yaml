# THIS IS AN EXAMPLE IOHUB CONFIG FILE. 
#
# THIS FILE SHOULD BE COPIED TO YOUR EXPERIMENT DIRECTORY WHERE IT WILL 
# BE PICKED UP BY THE EXAMPLE EXPERIMENT. 
# 
# THIS EXAMPLE YAML CONFIG FILE ENABLES ALL DEVICES, INCLUDING AN 
# EYE TRACKER. MINIMUM CHANGES NEEDED TO GET THIS RUNNING ARE:
#     1) SEARCH FOR 'MY_EXPERIMENT_PATH' and replace with the path to your
#        experiment, or to where you want your data files saved. This is
#        located in TWO places in the file.
#     2) SEARCH for 'MY_EYETRACKER_CLASS' and replace with one of the two 
#         example class paths given (one is for eyelink, the other for smi) 
#
#-----------------------------------------------------------------------
#
# ipcCoder = 'ujson' | 'msgpack'
#                                                               
# Select which encoder / decoder to use for sending
# data in UDP packets. msgpack seems as fast a ujson, but 
# the same events are about 30 - 40% smaller in size, so msgpack
# is set as default.
# 
ipcCoder: msgpack
#
# asyncClient = True | False
#                                                               
# Note: ONLY False is currenly supported.
# i.e. client calls to hub are blocking calls
# in experiment program. If set to True, will ( should ? ) raise exception!
# 
asyncClient: False
#
# global_event_buffer: unsigned int
#
# The number of events held in the ioHub device wide integrated event deque. 
# These are events that have been retrieved from the individual device event deque's 
# and converted to normalized ioHub event objects, ready to be retrieved by 
# the experiment runtime. If the exp. runtime is getting events every, say 20 msec,
# then there should never really be more than maybe 30 events (inc. eye samples)
# in the queue at most, but having a high value for the maximum size does not hurt.
#
# If the deque becomes full, each new event added removes one oldest event from the
# deque to make room for it.
#
global_event_buffer: 2048
#
# udpPort: unsigned int
# Port number that the ioHub server should receive UDP requests from the experiment client on.
#
udpPort: 9000
#
# monitor_devices lists the devices that are to be included for event
# streaming, saving, or experiment interaction. 
#
# Currently, Keyboard, Mouse, ParallelPort (on the Experiment PC) and EyeTracker
# (via the pyEyeTrackerInterface) are supported.
#
# If a device is enabled, then it can be monitored and events can be
# streamed to the experiment application and / or saved to a file.
#
# Currently, if a device is enabled and events are being streamed or saved,
# ALL event types for that device are activated. This will be enhanced so you can
# control what event types you want to stream and / or save to file individually
# in a future release.
#
# - device_class : name of the ioHub device class to instantiate. This is the literal 
#                  platform independent device class name, so spelling and capilatization
#                  are critical.
#
# - enabled : have the ioHub monitor that device type
#
# - name: The name you want to give the device. Can be any valid python attribute name
#         up to 24 characters in length. So name can not 'start' with a number,
#         and can only contain letters a-z, A-Z, and numbers 0-9
#
# - instance_code: This should be a unique string up to 48 characters in length. Generally using
#                  the devices serial number is a safe bet, otherwise make something up that will be
#                  unique across all devices for your site. 
#                   
#
# - event_buffer_length: maximum length of event buffer for the device in the ioHub. 
#                      Once it is full, oldest first events are dropped from the
#                      buffer to make room for new ones.
#
# - stream_events: Enables events from this device being included in events sent when the
#   ioHubClient calls getEvents()
#
# - save_events: Enables saving of events to file, based on the ioDataStore config settings.
#
# - device_timer: Specifies that a periodic timer should be created for this device.
#   - interval: the sec.msec interval that the timer should be run at. 0.001 is 1 msec, 0.0001 specifies 
#               100 usec interval, however on Windows 7 64 bit with an i5 mobile, it seemed I could not get intervals
#               below 250-300 usec, so I suggest anything below 1 msec be tested for validity on your system.
#
monitor_devices:
    device:
        device_class: Keyboard
        name: ExperimentPCkeyboard
        instance_code: kb_serial_number
        saveEvents: True
        streamEvents: True
        event_buffer_length: 256
    device:
        device_class: Mouse
        name: ExperimentPCmouse
        instance_code: mouse_serial_number
        saveEvents: True
        streamEvents: True
        event_buffer_length: 256
    device:
        device_class: ParallelPort
        name: ExperimentPCpport
        instance_code: computer_serial_number+pport
        saveEvents: True
        streamEvents: True
        base_address: 0x378
        event_buffer_length: 256
        device_timer:
            interval: 0.0001
    device:
        device_class: ExperimentDevice
        name: PsychoPy
        instance_code: computer_serial_number+psychopy
        saveEvents: True
        event_buffer_length: 64
    device: &DisplaySettings
        device_class: Display 
        name: calibrationPlane
        instance_code: display_serial_number
        psychopy_config_file: unknown
        # left,top,right,bottom bounds of the  calibration surface in calibration units (pixels, degrees, etc)
        calibration_surface_bounds:
            left: -10.0
            top: 10.0
            right: 10.0
            bottom: -10.0 
        calibration_surface_bounds_unit_type: degrees
        physical_calibration_surface_unit_type: mm
        # - width and height of calibration plane in mm
        physical_calibration_surface_dimensions:
            width: 900
            height: 600
        # - the orthoganal center point relative to line of site in mm
        orthoganal_eye_to_physical_calibration_surface_location: 
            horizontal: 450
            vertical: 300
        #  
        #  default_eye_plane_distance
        #
        #  distance of eye being tracked in mm 
        # (from horiz. center point of both eyes if binocular).
        #   1 point == distance to plane x,y center : plane_center
        #   2 point == distance to horizontal midline,
        #     (top, bottom) : top_center, bottom_center
        #   4 point == distance to 4 corners of plane 
        #     : top_left,top_right,bottom_left,bottom_right   
        default_eye_physical_calibration_surface_distance: 
            top_center: 600
            bottom_center: 660    
        #
        # Inter Pupil Distance (IPD) in mm
        #
        # Does not need to be super accurate, can just be used by
        # eye_plane_distance in binocular case to expand out to distances
        # for both eyes if significant.  
        #
        IPD: 30.0
        #
        # head_stationary: True | False
        #  
        # - Is the above eye distance info actually
        #   useful? True == Yes, False == No. 
        #   i.e. True == head is fixed, False == head is free to move
        head_stationary: True          
    device:
         device_class: MY_EYETRACKER_CLASS
#        device_class: eyeTrackerInterface.HW.SMI.iViewX.EyeTracker
#        device_class: eyeTrackerInterface.HW.SR_Research.EyeLink.EyeTracker
        name: tracker
        instance_code: et_serial_number
        saveEvents: True
        streamEvents: True
        event_buffer_length: 2048
        device_timer:
            interval: 0.0005        
        #
        # display_settings: provides a copy of all the Display Device settings
        #
        display_settings: *DisplaySettings
        #
        # runtime_settings: contains settings that are used during eye tracker initialization 
        #                   to set various values in the eye tracker configuration so that they 
        #                   do not need to be set explitiedly by sending commands via the the 
        #                   send command menthod. REfer to your devices implemention on 
        #                   which runtime_setting and values are supported.
        #
        runtime_settings:
            #
            # Save native eye tracker data file to this local directory
            #
            save_native_data_file_to: C:\MY_EXPERIMENT_PATH\
            #
            # Default native data file name (NOT including appropriate file name extenstion / postfix)            
            #
            default_native_data_file_name: default
            #
            # EyeTrackerConfig['sampling_rate'] = FLOAT_HZ
            # 
            # Sampling rate to track at in Hz. Must be supported by eye tracker being used. ;)
            #
            sampling_rate: 60.0
            #
            # EyeTrackerConfig['track_eyes']=('BINOC' | 'MONO', [ 'MEAN' | 'SIM' ])
            #
            # which eyes to track?
            # BINOC == binocular, seperate data provided for both eyes
            # BINOC, AVERAGE == record binocular data, but ioHub sends
            #      mono sample stream of averaged data from 2 eye fields. 
            #     (TO DO: not yet implemented) 
            # BINOC, SIM == binocular, 
            #     running in simulation mode supported by tracker
            # MONO == monocular , eye selected during setup of system.
            #    'LEFT' or 'RIGHT' can be used instead of 'MONO'
            #    to request a specific eye, but this can not be guarenteed.
            # MONO, SIM == monocular recording,
            #    running in simulation mode supported by tracker
            #    'LEFT' or 'RIGHT' can be used instead of 'MONO'
            #    to request a specific eye, but this can not be guarenteed.
            track_eyes: BINOC
            #
            # default_calibration: NONE | 3P_HOR | 3P_VERT | 3P_2D | 
            #                      4P_CORNERS | 4P_SIDE_CENTERS |  
            #                      5P_X | 5P_+ | 9P | 13_P
            #
            # Defines the default calibration grid to use. Not all options
            # Will be available for all eye trackers. Check with the eye
            # tracker implementation otes for the available options for 
            # your tracker.  
            #
            default_calibration: 9P
            #
            # vog_settings: 
            # 
            # Setting related specifically to video based eye tracking systems.
            #
            # tracking_mode: pupil-cr | pupil-only
            #
            # tracking_mode specifies which features, or signals, are tracked while
            # while calculating eye position. 
            # pupil-cr inications that the pupil and one or more corneal reflections are 
            # used during image processing. 
            # pupil-only indicates that the eye trcacker uses only the pupil to determine 
            # eye position.
            # Your eye tracker may only support one of these modes; check your implementation
            # specific documentation for details.
            #
            # pupil_illumination: dark | bright | mixed
            #
            # pupil_illumination specifes the illumination type being used for the tracker.
            # (dark == off-axis, bright == on-axis, mixed == some form of alternating dark , bright)
            # while most eye trackers have a fixed, pupil_illumination type, some allow this to be
            # changed whileusing the same core system. Again, check with your trackers implementation doc
            # for details. 
            #
            # pupil_center_algorithm: centroid | circle_fit | elipse_fit | *implementation_defined*
            #
            # pupil_center_algorithm defines the algorithm to use for determining the center the the pupil 
            # mass by the eye tracker image processing layer. Some eye trackers support > 1 algorithm
            # that is user selectable, so this setting allows you to secify which algorithm to use.
            # Again, check with your eye tracker implementation for the valid options for your implementation.
            # *implementation_defined* indicates that values not listed here may be specified
            # by a specific implementation and used in a configuration file.  
            vog_settings:
                tracking_mode: pupil-cr
                pupil_illumination: dark
                pupil_center_algorithm: centroid
            #
            # auto_calibration: True | False
            #
            # should tracker auto accept fixations (True) or should fixations
            # be manually accepted by a button or key press (False)
            #
            auto_calibration: True 
            #
            # runtime_filtering: ANY | LINK | FILE | ANALOG | SERIAL : NONE | LEVEL_1 | LEVEL_2 |
            #                                                          LEVEL_3 | LEVEL_4 | LEVEL_5
            #
            # Sets runtime filtering of the sample stream for the system
            # 0 == no filtering, see specific interface implementation 
            # 'ANY' == set the provided filter level for any data streams that
            # can be filtered. Some eye trackers support independent filtering
            # of different data streams, for example the real-time sample feed
            # vs. the sample stream saved to file. 
            # Therefore 'ANY' may also be 'LINK' or 'FILE' or 'ANALOG', 
            # as examples, to set a specific streams filter level, with
            # different entries for different stream values. Again, 
            # please see specific interfaces implementation page for specifics.
            # Safest bet is to use 'ANY' if you are unsure, as this must be supported.
            runtime_filtering:
                ANY: 0  
#
# ioDataStore Configuration Settings
# - enabled: True = ioDataStore module will be initialized and a dataStore file created., False = ignore config settings.
# - filename: name of file to save
# - filepath: absolution path of file to save.  CURRENT_DIR == location of experiment script.
# - storage_type: Currently only 'pytables' is supported. That may not be a bad thing. ;) 
#                 However we may want to support different file types / formats in the future.
# - multiple_experiments: If True, a single ioStoreFile can save multiple experiments work of data. 
#                         False == 1 experiment session per file.
# - flush_interval: How often should explicit flush be called by ioHub ( in number of events ):
#                   n == 0 : after every event
#                   n  > 0 : after every n events
#                   n  < 0 : only when IOHUB_FLUSH_EVENTS command is received 
#                            from experiment (TO DO: not yet implemented ) 
#
ioDataStore:
    enable: True
    filename: default
    filepath: C:\MY_EXPERIMENT_PATH\
    storage_type: pytables
    multiple_experiments: True
    flush_interval: 64
